{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80566e56",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After today's lesson you should be able to:\n",
    "- Implement geodemographic and regionalization clustering\n",
    "\n",
    "This week's lesson is a simplied version of:  \n",
    "- The [Week 8 on Linear Regression from General Assembly's Data Science Course](https://github.com/justmarkham/DAT4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c6f95",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183f0b3",
   "metadata": {},
   "source": [
    "## Example: Advertising Data\n",
    "\n",
    "Let's take a look at some data, ask some questions about that data, and then use linear regression to answer those questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8efb8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/justmarkham/scikit-learn-videos/master/data/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5200ad",
   "metadata": {},
   "source": [
    "What are the **features**?\n",
    "- TV: advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "- Radio: advertising dollars spent on Radio\n",
    "- Newspaper: advertising dollars spent on Newspaper\n",
    "\n",
    "What is the **response**?\n",
    "- Sales: sales of a single product in a given market (in thousands of widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca3f51",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print the shape of the DataFrame\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06471da",
   "metadata": {},
   "source": [
    "There are 200 **observations**, and thus 200 markets in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8584596",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "data.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter', x='Radio', y='Sales', ax=axs[1])\n",
    "data.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9171e9",
   "metadata": {},
   "source": [
    "## Questions About the Advertising Data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets this widget. The company might ask you the following: On the basis of this data, how should we spend our advertising money in the future?\n",
    "\n",
    "This general question might lead you to more specific questions:\n",
    "1. Is there a relationship between ads and sales?\n",
    "2. How strong is that relationship?\n",
    "3. Which ad types contribute to sales?\n",
    "4. What is the effect of each ad type of sales?\n",
    "5. Given ad spending in a particular market, can sales be predicted?\n",
    "\n",
    "We will explore these questions below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ba337",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression is an approach for predicting a **quantitative response** using a **single feature** (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What does each term represent?\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**. To create your model, you must \"learn\" the values of these coefficients. And once we've learned these coefficients, we can use the model to predict Sales!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe6f89",
   "metadata": {},
   "source": [
    "## Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "Generally speaking, coefficients are estimated using the **least squares criterion**, which means we are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb33857",
   "metadata": {},
   "source": [
    "</figure>\n",
    "<img src=\"https://www.dropbox.com/s/65mihrlxzdve48g/08_estimating_coefficients.png?dl=1\" alt=\"drawing\" width=\"500\" style=\"display: block; margin: 0 auto\"/>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb9300",
   "metadata": {},
   "source": [
    "What elements are present in the diagram?\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the distances between the observed values and the least squares line.\n",
    "\n",
    "How do the model coefficients relate to the least squares line?\n",
    "- $\\beta_0$ is the **intercept** (the value of $y$ when $x$=0)\n",
    "- $\\beta_1$ is the **slope** (the change in $y$ divided by change in $x$)\n",
    "\n",
    "Here is a graphical depiction of those calculations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac7c71",
   "metadata": {},
   "source": [
    "</figure>\n",
    "<img src=\"https://www.dropbox.com/s/bg7z9k3mne5zop9/08_slope_intercept.png?dl=1\" alt=\"drawing\" width=\"500\" style=\"display: block; margin: 0 auto\"/>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7bcdb",
   "metadata": {},
   "source": [
    "Let's use **Statsmodels** to estimate the model coefficients for the advertising data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05dc286",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# this is the standard import if you're using \"formula notation\" (similar to R)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# create a fitted model in one line\n",
    "lm = smf.ols(formula='Sales ~ TV', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002bebc",
   "metadata": {},
   "source": [
    "## Interpreting Model Coefficients\n",
    "\n",
    "How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.047537 \"unit\" increase in Sales.\n",
    "- Or more clearly: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.537 widgets.\n",
    "\n",
    "Note that if an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52494ebb",
   "metadata": {},
   "source": [
    "## Using the Model for Prediction\n",
    "\n",
    "Let's say that there was a new market where the TV advertising spend was **$50,000**. What would we predict for the Sales in that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.032594 + 0.047537 \\times 50$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e449be8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# manually calculate the prediction\n",
    "7.032594 + 0.047537*50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dba51f",
   "metadata": {},
   "source": [
    "Thus, we would predict Sales of **9,409 widgets** in that market.\n",
    "\n",
    "Of course, we can also use Statsmodels to make the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62a95d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# you have to create a DataFrame since the Statsmodels formula interface expects it\n",
    "X_new = pd.DataFrame({'TV': [50]})\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ee91b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# use the model to make predictions on a new value\n",
    "lm.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5221b2",
   "metadata": {},
   "source": [
    "## Plotting the Least Squares Line\n",
    "\n",
    "Let's make predictions for the **smallest and largest observed values of x**, and then use the predicted values to plot the least squares line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d845b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with the minimum and maximum values of TV\n",
    "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf839e5d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for those x values and store them\n",
    "preds = lm.predict(X_new)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992842c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# first, plot the observed data\n",
    "data.plot(kind='scatter', x='TV', y='Sales')\n",
    "\n",
    "# then, plot the least squares line\n",
    "plt.plot(X_new, preds, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174eaf0d",
   "metadata": {},
   "source": [
    "## Hypothesis Testing and p-values\n",
    "Generally speaking, you start with a **null hypothesis** and an **alternative hypothesis** (that is opposite the null). Then, you check whether the data supports **rejecting the null hypothesis** or **failing to reject the null hypothesis**.\n",
    "\n",
    "(Note that \"failing to reject\" the null is not the same as \"accepting\" the null hypothesis. The alternative hypothesis may indeed be true, except that you just don't have enough data to show that.)\n",
    "\n",
    "As it relates to model coefficients, here is the conventional hypothesis test:\n",
    "- **null hypothesis:** There is no relationship between TV ads and Sales (and thus $\\beta_1$ equals zero)\n",
    "- **alternative hypothesis:** There is a relationship between TV ads and Sales (and thus $\\beta_1$ is not equal to zero)\n",
    "\n",
    "How do we test this hypothesis? Intuitively, we reject the null (and thus believe the alternative) if the 95% confidence interval **does not include zero**. Conversely, the **p-value** represents the probability that the coefficient is actually zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190274a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print the p-values for the model coefficients\n",
    "lm.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74135616",
   "metadata": {},
   "source": [
    "If the 95% confidence interval **includes zero**, the p-value for that coefficient will be **greater than 0.05**. If the 95% confidence interval **does not include zero**, the p-value will be **less than 0.05**. Thus, a p-value less than 0.05 is one way to decide whether there is likely a relationship between the feature and the response. (Again, using 0.05 as the cutoff is just a convention.)\n",
    "\n",
    "In this case, the p-value for TV is far less than 0.05, and so we **believe** that there is a relationship between TV ads and Sales.\n",
    "\n",
    "Note that we generally ignore the p-value for the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef63ab6",
   "metadata": {},
   "source": [
    "## How Well Does the Model Fit the data?\n",
    "\n",
    "The most common way to evaluate the overall fit of a linear model is by the **R-squared** value. R-squared is the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the **null model**. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
    "\n",
    "R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. Here's an example of what R-squared \"looks like\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7177e91",
   "metadata": {},
   "source": [
    "\n",
    "</figure>\n",
    "<img src=\"https://www.dropbox.com/s/p937tyo5w16ssuu/08_r_squared.png?dl=1\" alt=\"drawing\" width=\"500\" style=\"display: block; margin: 0 auto\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a134cf",
   "metadata": {},
   "source": [
    "You can see that the **blue line** explains some of the variance in the data (R-squared=0.54), the **green line** explains more of the variance (R-squared=0.64), and the **red line** fits the training data even further (R-squared=0.66). (Does the red line look like it's overfitting?)\n",
    "\n",
    "Let's calculate the R-squared value for our simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c564326",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print the R-squared value for the model\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cf31b",
   "metadata": {},
   "source": [
    "Is that a \"good\" R-squared value? It's hard to say. The threshold for a good R-squared value depends widely on the domain. Therefore, it's most useful as a tool for **comparing different models**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12f99d",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features. This is called **multiple linear regression**:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient. In this case:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$\n",
    "\n",
    "Let's use Statsmodels to estimate these coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcef6c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create a fitted model with all three features\n",
    "lm = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47f5cd",
   "metadata": {},
   "source": [
    "How do we interpret these coefficients? For a given amount of Radio and Newspaper ad spending, an **increase of $1000 in TV ad spending** is associated with an **increase in Sales of 45.765 widgets**.\n",
    "\n",
    "A lot of the information we have been reviewing piece-by-piece is available in the model summary output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46765a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print a summary of the fitted model\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1eabae",
   "metadata": {},
   "source": [
    "What are a few key things we learn from this output?\n",
    "\n",
    "- TV and Radio have significant **p-values**, whereas Newspaper does not. Thus we reject the null hypothesis for TV and Radio (that there is no association between those features and Sales), and fail to reject the null hypothesis for Newspaper.\n",
    "- TV and Radio ad spending are both **positively associated** with Sales, whereas Newspaper ad spending is **slightly negatively associated** with Sales. (However, this is irrelevant since we have failed to reject the null hypothesis for Newspaper.)\n",
    "- This model has a higher **R-squared** (0.897) than the previous model, which means that this model provides a better fit to the data than a model that only includes TV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040eeb75",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "How do I decide **which features to include** in a linear model? Here's one idea:\n",
    "- Try different models, and only keep predictors in the model if they have small p-values.\n",
    "- Check the collinearity between predictors\n",
    "- Check whether the R-squared value goes up when you add new predictors.\n",
    "\n",
    "What are the **drawbacks** to this approach?\n",
    "- Linear models rely upon a lot of **assumptions** (such as the features being independent), and if those assumptions are violated (which they usually are), R-squared and p-values are less reliable.\n",
    "- Using a p-value cutoff of 0.05 means that if you add 100 predictors to a model that are **pure noise**, 5 of them (on average) will still be counted as significant.\n",
    "- R-squared is susceptible to **overfitting**, and thus there is no guarantee that a model with a high R-squared value will generalize. Below is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e8bd6",
   "metadata": {},
   "source": [
    "First, let's check the collinearity between TV, radio, and newspaper. What would it mean for deciding on a strategy, if for instance, the correlation between TV and Radio were 1? A good rule of thumb is if the Variance Inflation Factor (VIF) $\\frac{1}{1-R^2}$ is 5 or above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37130449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad063768",
   "metadata": {},
   "source": [
    "Since the correlation is pretty low here, we should not be too worried. As a rule of thumb, anything about 0.6 or above, I will do Variance Inflation Factor tests, where we find\n",
    "$$\n",
    "VIF = \\frac{1}{1-R_i^2}\n",
    "$$\n",
    "where $i$ is the independent variable in question and we regress it on all the other independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_vif=smf.ols(formula='Radio ~ Newspaper + Sales', data=data).fit()\n",
    "print(\"VIF for Radio is \", 1/(1-lm_vif.rsquared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3497d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# only include TV and Radio in the model\n",
    "lm = smf.ols(formula='Sales ~ TV + Radio', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21dbe6-ceae-45a8-8a7b-b2f8c26ad494",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51287c75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# add Newspaper to the model (which we believe has no association with Sales)\n",
    "lm = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afbb9d",
   "metadata": {},
   "source": [
    "**R-squared will always increase as you add more features to the model**, even if they are unrelated to the response. Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
    "\n",
    "There is alternative to R-squared called **adjusted R-squared** that penalizes model complexity (to control for overfitting), but it generally [under-penalizes complexity](http://scott.fortmann-roe.com/docs/MeasuringError.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.rsquared_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f48c522",
   "metadata": {},
   "source": [
    "## Linear Regression in scikit-learn\n",
    "\n",
    "Let's redo some of the Statsmodels code above in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aff3df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "X = data[feature_cols]\n",
    "y = data.Sales\n",
    "y = data['Sales']\n",
    "\n",
    "# follow the usual sklearn pattern: import, instantiate, fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print intercept and coefficients\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6235d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# pair the feature names with the coefficients\n",
    "# zip(feature_cols, lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907b8f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# predict for a new observation\n",
    "lm.predict(np.array([100, 25, 25]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa862f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate the R-squared\n",
    "lm.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6737e",
   "metadata": {},
   "source": [
    "Note that **p-values** and **confidence intervals** are not (easily) accessible through scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab4200",
   "metadata": {},
   "source": [
    "## Handling Categorical Predictors with Two Categories\n",
    "\n",
    "Up to now, all of our predictors have been numeric. What if one of our predictors was categorical?\n",
    "\n",
    "Let's create a new feature called **Size**, and randomly assign observations to be **small or large**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91696e84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "# create a Series of booleans in which roughly half are True\n",
    "nums = np.random.rand(len(data))\n",
    "mask_large = nums > 0.5\n",
    "\n",
    "# initially set Size to small, then change roughly half to be large\n",
    "data['Size'] = 'small'\n",
    "data.loc[mask_large, 'Size'] = 'large'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a278ea9",
   "metadata": {},
   "source": [
    "For scikit-learn, we need to represent all data **numerically**. If the feature only has two categories, we can simply create a **dummy variable** that represents the categories as a binary value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dddf5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create a new Series called IsLarge\n",
    "data['IsLarge'] = data.Size.map({'small':0, 'large':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d6f40",
   "metadata": {},
   "source": [
    "Let's redo the multiple linear regression and include the **IsLarge** predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49dcdd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper', 'IsLarge']\n",
    "X = data[feature_cols]\n",
    "y = data.Sales\n",
    "\n",
    "# instantiate, fit\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print coefficients\n",
    "print(list(zip(feature_cols, lm.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0fa9a",
   "metadata": {},
   "source": [
    "How do we interpret the **IsLarge coefficient**? For a given amount of TV/Radio/Newspaper ad spending, being a large market is associated with an average **increase** in Sales of 57.42 widgets (as compared to a Small market, which is called the **baseline level**).\n",
    "\n",
    "What if we had reversed the 0/1 coding and created the feature 'IsSmall' instead? The coefficient would be the same, except it would be **negative instead of positive**. As such, your choice of category for the baseline does not matter, all that changes is your **interpretation** of the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb429dc",
   "metadata": {},
   "source": [
    "## Handling Categorical Predictors with More than Two Categories\n",
    "\n",
    "Let's create a new feature called **Area**, and randomly assign observations to be **rural, suburban, or urban**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22f931",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# assign roughly one third of observations to each group\n",
    "nums = np.random.rand(len(data))\n",
    "mask_suburban = (nums > 0.33) & (nums < 0.66)\n",
    "mask_urban = nums > 0.66\n",
    "data['Area'] = 'rural'\n",
    "data.loc[mask_suburban, 'Area'] = 'suburban'\n",
    "data.loc[mask_urban, 'Area'] = 'urban'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a5981",
   "metadata": {},
   "source": [
    "We have to represent Area numerically, but we can't simply code it as 0=rural, 1=suburban, 2=urban because that would imply an **ordered relationship** between suburban and urban (and thus urban is somehow \"twice\" the suburban category).\n",
    "\n",
    "Instead, we create **another dummy variable**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f50d75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create three dummy variables using get_dummies, then exclude the first dummy column\n",
    "area_dummies = pd.get_dummies(data.Area, prefix='Area').iloc[:, 1:]\n",
    "\n",
    "# concatenate the dummy variable columns onto the original DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "data = pd.concat([data, area_dummies], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66258746",
   "metadata": {},
   "source": [
    "Here is how we interpret the coding:\n",
    "- **rural** is coded as Area_suburban=0 and Area_urban=0\n",
    "- **suburban** is coded as Area_suburban=1 and Area_urban=0\n",
    "- **urban** is coded as Area_suburban=0 and Area_urban=1\n",
    "\n",
    "Why do we only need **two dummy variables, not three?** Because two dummies captures all of the information about the Area feature, and implicitly defines rural as the baseline level. (In general, if you have a categorical feature with k levels, you create k-1 dummy variables.)\n",
    "\n",
    "If this is confusing, think about why we only needed one dummy variable for Size (IsLarge), not two dummy variables (IsSmall and IsLarge).\n",
    "\n",
    "Let's include the two new dummy variables in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf482ae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper', 'IsLarge', 'Area_suburban', 'Area_urban']\n",
    "X = data[feature_cols]\n",
    "y = data.Sales\n",
    "\n",
    "# instantiate, fit\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print coefficients\n",
    "print(list(zip(feature_cols, lm.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c920c5",
   "metadata": {},
   "source": [
    "How do we interpret the coefficients?\n",
    "- Holding all other variables fixed, being a **suburban** area is associated with an average **decrease** in Sales of 106.56 widgets (as compared to the baseline level, which is rural).\n",
    "- Being an **urban** area is associated with an average **increase** in Sales of 268.13 widgets (as compared to rural).\n",
    "\n",
    "**A final note about dummy encoding:** If you have categories that can be ranked (i.e., strongly disagree, disagree, neutral, agree, strongly agree), you can potentially use a single dummy variable and represent the categories numerically (such as 1, 2, 3, 4, 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ca88b",
   "metadata": {},
   "source": [
    "## What Didn't We Cover?\n",
    "\n",
    "- Detecting collinearity\n",
    "- Diagnosing model fit\n",
    "- Transforming predictors to fit non-linear relationships\n",
    "- Interaction terms\n",
    "- Assumptions of linear regression\n",
    "- And so much more!\n",
    "\n",
    "You could certainly go very deep into linear regression, and learn how to apply it really, really well. It's an excellent way to **start your modeling process** when working a regression problem. However, it is limited by the fact that it can only make good predictions if there is a **linear relationship** between the features and the response, which is why more complex methods (with higher variance and lower bias) will often outperform linear regression.\n",
    "\n",
    "Therefore, we want you to understand linear regression conceptually, understand its strengths and weaknesses, be familiar with the terminology, and know how to apply it. However, we also want to spend time on many other machine learning models, which is why we aren't going deeper here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d912b12",
   "metadata": {},
   "source": [
    "## Q.1\n",
    "\n",
    "\n",
    "The chief of automobile maintenance for the city of Normal feels that maintenance costs on high-mileage cars are much higher than those costs for low-mileage cars. The maintenance chief regresses yearly maintenance costs for a sample of 200 cars on each car's total mileage for the year. She finds the following: \n",
    "$$\n",
    "\\hat{Y} = \\$50 + 0.030X\n",
    "$$\n",
    "where $Y$ is the maintenance cost (in dollars) for the year and $X$ is the mileage on the car. \n",
    "\n",
    "**(a)** Is there a relationship between maintenance costs and mileage? (1 pt)\n",
    "\n",
    "**(b)** What are the predicted maintenance costs of a car with 50,000 miles? (1 pt) \n",
    "\n",
    "**(c)** The maintenance chief considers 1,000 dollars in maintenance a year excessive. For this criterion, how many miles will generate maintenance costs of 1,000 dollars?  (2 pt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7da401",
   "metadata": {},
   "source": [
    "WRITE YOUR ANSWERS DOWN HERE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431840a",
   "metadata": {},
   "source": [
    "## Q.2\n",
    "The Wisconsin Association of School Districts is interested in the relationship between school district population and funding for schools. From a sample of 300 school districts, the association uses simple regression to predict total school district expenditures in dollars ($Y$) using the school district's population ($X$ = number of persons residing in the district). It finds \n",
    "$$\n",
    "\\hat{Y} = 4,566 + 824X\n",
    "$$\n",
    "Where the $R^2$ = 0.78, p-value for the intercept is 0.23 and the p-value for the slope is 0.01. \n",
    "\n",
    "Express in plain English the interpretations of the following in this scenario: \n",
    "\n",
    "**(a)** the intercept (1 pt)\n",
    "\n",
    "**(b)** the slope (1 pt)\n",
    "\n",
    "**(c)** the p-value for the intercept (1 pt)\n",
    "\n",
    "**(d)** the p-value for the slope (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da2948",
   "metadata": {},
   "source": [
    "## Q.3\n",
    "Dick Engstrom and Mike MacDonald are interested in the relationship between African-American representation on city councils and the structure of the electoral system. Their independent variable is the percentage of African Americans in the population; their dependent variable is the percentage of seats on the city council that are held by African Americans. Engstrom and MacDonald want to compare representation under single-member district election systems and under at-large election systems. They get the following results: \n",
    "\n",
    "**At-large systems**\n",
    "$$\n",
    "\\hat{Y} = 0.348 + 0.495X\n",
    "$$ with $R^2$ = 0.34\n",
    "\n",
    "**Single-Member District System**\n",
    "$$\n",
    "\\hat{Y} = -0.832 + 0.994X\n",
    "$$ with $R^2$ = 0.816\n",
    "\n",
    "For each equation, interpret the slope, intercept, and $R^2$. Get the predicted city council representation of a city with 25% African-American population under both systems. What can you say about the relative representation of African Americans under each type of system? (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e873cc",
   "metadata": {},
   "source": [
    "## Q.4\n",
    "\n",
    "We would like to predict the mileage per gallon (`mpg`) for a sample of cars and evaluate our model. We will be using the `mtcars.csv` dataset (see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e21504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfcars = pd.read_csv('https://gist.githubusercontent.com/seankross/a412dfbd88b3db70b74b/raw/5f23f993cd87c283ce766e7ac6b329ee7cc2e1d1/mtcars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd163be",
   "metadata": {},
   "source": [
    "Now, we need to choose ONE variable that we think will be good predictors for the dependent variable `mpg`.\n",
    "\n",
    "**(a)**: Pick ONE variable to use as a predictor for simple linear regression. Create a markdown cell below and discuss your reasons. You may want to justify this with some visualizations. Is there a second variable you'd like to use as well, say for multiple linear regression with two predictors? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14461e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d2b22",
   "metadata": {},
   "source": [
    "**(b)**: Fit your dependent and independent variables using simple linear regression. Print out the regression summary and explain what the intercept, coefficients, $R^2$, and p-values for each outcome tells us. Plot the data and the prediction.  (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf969387",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# Fit your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b608b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# Print the results summary from your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# Plot your data and the prediction here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea95550",
   "metadata": {},
   "source": [
    "## Q.5\n",
    "\n",
    "Fit the data using multiple linear regression with TWO predictors. Create two models with two predictors each. Use these models to make `mpg` predictions. Print out the regression summary and explain what the intercept, coefficients, $R^2$, and p-values for each outcome tells us. Plot the data and the predictions (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# Fit your TWO models here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa141249",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# Print the results summary from your TWO models here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ddfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# Plot your data and the predictions from your TWO models here (separately)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e0d64",
   "metadata": {},
   "source": [
    "How do the results from the two models differ? What can you say about which model is better in terms of prediction? (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8c269",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
